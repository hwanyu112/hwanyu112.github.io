---
title: 'A Call for New Recipes to Enhance Spatial Reasoning in MLLMs'
authors:
- Huanyu Zhang*
- Chengzu Li*
- Wenshan Wu
- Shaoguang Mao
- Yan xia
- Ivan VuliÄ‡ Furu Wei
- Zhang Zhang
- Liang Wang
- Tieniu Tan
- Furu Wei
date: '2025-04-21'
publishDate: '2025-04-21T09:39:32.680953Z'
publication_types:
- article-journal
publication: '*arXiv preprint arXiv:2504.15037
*'

abstract: Multimodal Large Language Models (MLLMs) have demonstrated impressive performance in general vision-language tasks. However, recent studies have exposed critical limitations in their spatial reasoning capabilities. This deficiency in spatial reasoning significantly constrains MLLMs' ability to interact effectively with the physical world, thereby limiting their broader applications. We argue that spatial reasoning capabilities will not naturally emerge from merely scaling existing architectures and training methodologies. Instead, this challenge demands dedicated attention to fundamental modifications in the current MLLM development approach. In this position paper, we first establish a comprehensive framework for spatial reasoning within the context of MLLMs. We then elaborate on its pivotal role in real-world applications. Through systematic analysis, we examine how individual components of the current methodology-from training data to reasoning mechanisms-influence spatial reasoning capabilities. This examination reveals critical limitations while simultaneously identifying promising avenues for advancement. Our work aims to direct the AI research community's attention toward these crucial yet underexplored aspects. By highlighting these challenges and opportunities, we seek to catalyze progress toward achieving human-like spatial reasoning capabilities in MLLMs.

url_pdf: 'https://arxiv.org/pdf/2504.15037
'

tags:
- Multimodal Reasoning
featured: true

image:
  caption: 'By defining spatial reasoning in MLLMs and analyzing limitations in the current recipe, we advocate for new recipes to enhance spatial reasoning, unlocking the potential for applications.'
  focal_point: ""
  preview_only: false

---
{{% callout note %}}
By dynamically retrieving relevant information from an external knowledge base, our TimeRAF enhances prediction accuracy, leading to more precise zero-shot forecasting performance.
{{% /callout %}}